{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78aa3b0-2062-47bb-b176-cbe3673db8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d25f51e-9d26-44ce-91d8-45891159bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import safetensors.torch as st\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d30a1d9-ebfa-48b9-bf25-3ee742d1cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dictionary with metadata saved to SafeTensors format at: out/model_state_dict.safetensors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the output directory and checkpoint file name\n",
    "out_dir = 'out'\n",
    "checkpoint_file = 'ckpt.pt'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint_path = os.path.join(out_dir, checkpoint_file)\n",
    "checkpoint_dict = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Extract the model's state dictionary and additional metadata\n",
    "model_state_dict = checkpoint_dict['model']\n",
    "model_args = checkpoint_dict['model_args']\n",
    "config = checkpoint_dict['config']\n",
    "iter_num = str(checkpoint_dict['iter_num'])\n",
    "best_val_loss = str(checkpoint_dict['best_val_loss'])\n",
    "\n",
    "# Convert additional metadata to string if necessary (example for JSON serializable data)\n",
    "metadata = {\n",
    "    'model_args': json.dumps(model_args),\n",
    "    'config': json.dumps(config),\n",
    "    'iter_num': iter_num,\n",
    "    'best_val_loss': best_val_loss\n",
    "}\n",
    "\n",
    "# Clone tensors that share memory if necessary\n",
    "# Check and clone specific tensors known to share memory\n",
    "shared_tensors = ['_orig_mod.output.weight', '_orig_mod.tok_embeddings.weight']\n",
    "for tensor_name in shared_tensors:\n",
    "    if tensor_name in model_state_dict:\n",
    "        model_state_dict[tensor_name] = model_state_dict[tensor_name].clone()\n",
    "\n",
    "# Serialize the model's state dictionary along with metadata to SafeTensors format\n",
    "serialized_data = st.save(model_state_dict, metadata=metadata)\n",
    "\n",
    "# Write the serialized data to a file\n",
    "output_file_path = os.path.join(out_dir, 'model_state_dict.safetensors')\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    f.write(serialized_data)\n",
    "\n",
    "print(f\"Model state dictionary with metadata saved to SafeTensors format at: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c5e71-2470-4470-84ff-dd6a05e99a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
